cat('best number of nround is: ', best.nround)
} else{
best.max.depth <- max.depth
best.nround <- nround
}
best_xgb_fit <- xgboost(data = train_df,
label = label_train,
max.depth = best.max.depth,
eta = 0.3,
nround = best.nround,
objective = "multi:softmax",
num_class=3,
verbose = 0)
return(best_xgb_fit)
}
xgb_fit <- xgb_train(feature_train[train_index,],label_train[train_index],run.cv=run.cv)
pred_label_xgb <- xgb_test(xgb_fit,(feature_train[-train_index,])
mean(pred_label_xgb==label_train[-train_index])
pred_label_xgb <- xgb_test(xgb_fit,feature_train[-train_index,])
mean(pred_label_xgb==label_train[-train_index])
xgb_train <- function(dat_train, label_train, max.depth = 5, nround = 100,run.cv=F){
library(xgboost)
train_df <- data.matrix(dat_train)
label <- label_train
#train_df$label <- label_train
#train_df <- data.matrix(train_df)
if(run.cv){
list_max.depth <- c(5,20,50,100)
#list_max.depth <- c(5,10)
#list_eta <-  c()
#list_nround <- c(10,20)
list_nround <- c(10,25,100,200)
errors <- matrix(NA,nrow=length(list_max.depth),ncol = length(list_nround))
for(j in 1:length(list_max.depth)){
for(k in 1:length(list_nround)){
errors[j,k] <- xgb.cv.f(train_df, label,list_max.depth[j],list_nround[k])
}
}
row_index <- which(errors == min(errors), arr.ind = TRUE)[1]
col_index <- which(errors == min(errors), arr.ind = TRUE)[2]
best.max.depth <- list_max.depth[row_index]
best.nround <- list_nround[col_index]
print(errors)
cat('best number of max depth is: ',best.max.depth)
cat('\n')
cat('best number of nround is: ', best.nround)
} else{
best.max.depth <- max.depth
best.nround <- nround
}
best_xgb_fit <- xgboost(data = train_df,
label = label_train,
max.depth = best.max.depth,
eta = 0.3,
nround = best.nround,
objective = "multi:softmax",
num_class=3,
verbose = 0)
return(best_xgb_fit)
}
xgb_test <- function(model,dat_test, label_test){
pred_label <- predict(model, data.matrix(dat_test))
#return(mean(pred_label==label_test))
return(pred_label)
}
pred_label_xgb <- xgb_test(xgb_fit,feature_train[-train_index,])
mean(pred_label_xgb==label_train[-train_index])
xgb_fit <- xgb_train(feature_train[train_index,],label_train[train_index],run.cv=run.cv)
pred_label_xgb <- xgb_test(xgb_fit,feature_train[-train_index,])
mean(pred_label_xgb==label_train[-train_index])
xgb_train <- function(dat_train, label_train, max.depth = 5, nround = 100,run.cv=F){
library(xgboost)
train_df <- data.matrix(dat_train)
label <- label_train
#train_df$label <- label_train
#train_df <- data.matrix(train_df)
if(run.cv){
list_max.depth <- c(5,20,50,100)
#list_max.depth <- c(5,10)
#list_eta <-  c()
#list_nround <- c(10,20)
list_nround <- c(10,25,100,200)
errors <- matrix(NA,nrow=length(list_max.depth),ncol = length(list_nround))
for(j in 1:length(list_max.depth)){
for(k in 1:length(list_nround)){
errors[j,k] <- xgb.cv.f(train_df, label,list_max.depth[j],list_nround[k])
}
}
row_index <- which(errors == min(errors), arr.ind = TRUE)[1]
col_index <- which(errors == min(errors), arr.ind = TRUE)[2]
best.max.depth <- list_max.depth[row_index]
best.nround <- list_nround[col_index]
print(errors)
cat('best number of max depth is: ',best.max.depth)
cat('\n')
cat('best number of nround is: ', best.nround)
} else{
best.max.depth <- max.depth
best.nround <- nround
}
best_xgb_fit <- xgboost(data = train_df,
label = label_train,
max.depth = best.max.depth,
eta = 0.3,
nround = best.nround,
objective = "multi:softmax",
num_class=3,
verbose = 0)
return(best_xgb_fit)
}
xgb_test <- function(model,dat_test, label_test){
pred_label <- predict(model, data.matrix(dat_test))
#return(mean(pred_label==label_test))
return(pred_label)
}
load("sift5000_lbp_hog_gray.RData")
load("../Han Lin/output/sift5000_lbp_hog_gray.RData")
proportion = 0.75 # training set proportion
seed = 618 # set seed
n <- dim(sift5000_lbp_hog_grey)[1]
set.seed(seed)
train_index <- sample(n, n*proportion)
xgb_sift5000_lbp_hog_grey_fit_subset <-
xgb_train(sift5000_lbp_hog_grey[train_index,],label_train[train_index],run.cv=F)
tm <- system.time(pred_label <- xgb_test(xgb_sift5000_lbp_hog_grey_fit_subset,data.matrix(sift5000_lbp_hog_grey[-train_index,])))
mean(pred_label==label_train[-train_index])
setwd("~/Google Drive/ADS Project 3 Grp 3/Han Lin/output")
load("sift5000_lbp_hog_gray.RData")
setwd("~/Google Drive/ADS Project 3 Grp 3/Han Lin/output")
load("sift5000_lbp_hog_gray.RData")
getwd()
load("../Han Lin/output/sift5000_lbp_hog_gray.RData")
proportion = 0.75 # training set proportion
seed = 618 # set seed
n <- dim(sift5000_lbp_hog_grey)[1]
set.seed(seed)
train_index <- sample(n, n*proportion)
label_train <- as.vector(read.csv('../Han Lin/data/label_train.csv',as.is = T)[,2])
xgb_sift5000_lbp_hog_grey_fit_subset <-
xgb_train(sift5000_lbp_hog_grey[train_index,],label_train[train_index],run.cv=F)
xgb_train <- function(dat_train, label_train, max.depth = 5, nround = 100,run.cv=F){
library(xgboost)
train_df <- data.matrix(dat_train)
label <- label_train
#train_df$label <- label_train
#train_df <- data.matrix(train_df)
if(run.cv){
list_max.depth <- c(5,20,50,100)
#list_max.depth <- c(5,10)
#list_eta <-  c()
#list_nround <- c(10,20)
list_nround <- c(10,25,100,200)
errors <- matrix(NA,nrow=length(list_max.depth),ncol = length(list_nround))
for(j in 1:length(list_max.depth)){
for(k in 1:length(list_nround)){
errors[j,k] <- xgb.cv.f(train_df, label,list_max.depth[j],list_nround[k])
}
}
row_index <- which(errors == min(errors), arr.ind = TRUE)[1]
col_index <- which(errors == min(errors), arr.ind = TRUE)[2]
best.max.depth <- list_max.depth[row_index]
best.nround <- list_nround[col_index]
print(errors)
cat('best number of max depth is: ',best.max.depth)
cat('\n')
cat('best number of nround is: ', best.nround)
} else{
best.max.depth <- max.depth
best.nround <- nround
}
best_xgb_fit <- xgboost(data = train_df,
label = label_train,
max.depth = best.max.depth,
eta = 0.3,
nround = best.nround,
objective = "multi:softmax",
num_class=3,
verbose = 0)
return(best_xgb_fit)
}
xgb_sift5000_lbp_hog_grey_fit_subset <-
xgb_train(sift5000_lbp_hog_grey[train_index,],label_train[train_index],run.cv=F)
tm <- system.time(pred_label <- xgb_test(xgb_sift5000_lbp_hog_grey_fit_subset,data.matrix(sift5000_lbp_hog_grey[-train_index,])))
xgb_test <- function(model,dat_test, label_test){
pred_label <- predict(model, data.matrix(dat_test))
#return(mean(pred_label==label_test))
return(pred_label)
}
tm <- system.time(pred_label <- xgb_test(xgb_sift5000_lbp_hog_grey_fit_subset,data.matrix(sift5000_lbp_hog_grey[-train_index,])))
mean(pred_label==label_train[-train_index])
load(train_index)
load('../Han Lin/output/train_index.RData')
xgb_sift5000_lbp_hog_grey_fit_subset <-
xgb_train(sift5000_lbp_hog_grey[train_index,],label_train[train_index],run.cv=F)
tm <- system.time(pred_label <- xgb_test(xgb_sift5000_lbp_hog_grey_fit_subset,data.matrix(sift5000_lbp_hog_grey[-train_index,])))
mean(pred_label==label_train[-train_index])
df1<-data.frame(x=c('SIFT','SIFT+HOG','SIFT+HOG+LBP','SIFT+HOG+Gray256'),
y=c(0.8267,0.8633,0.878,0.88))
ggplot(df1,aes(x,y))+geom_line(aes(color="5"))
df1<-data.frame(x=c('SIFT','SIFT+HOG','SIFT+HOG+LBP','SIFT+HOG+Gray256'),
y=c(0.8267,0.8633,0.878,0.88))
df2<-data.frame(x=c('SIFT','SIFT+HOG','SIFT+HOG+LBP','SIFT+HOG+Gray256'),
y=c(0.8189,0.8667,0.877,0.89))
ggplot(df1,aes(x,y))+geom_line(aes(color="5"))+
geom_line(data=df2,aes(color="20"))+
train_index <- sort(sample(1:length(label_train),0.7*length(label_train)))
ggplot(df1,aes(x,y))+geom_line(aes(color="5"))+
geom_line(data=df2,aes(color="20"))
ggplot(df1,aes(x,y,group=group))+geom_line(aes(color="5"))+
geom_line(data=df2,aes(color="20"))
df1<-data.frame(x=c('SIFT','SIFT+HOG','SIFT+HOG+LBP','SIFT+HOG+Gray256'),
y=c(0.8267,0.8633,0.878,0.88),group=1)
df2<-data.frame(x=c('SIFT','SIFT+HOG','SIFT+HOG+LBP','SIFT+HOG+Gray256'),
y=c(0.8189,0.8667,0.877,0.89),group=1)
ggplot(df1,aes(x,y,group=group))+geom_line(aes(color="5"))+
geom_line(data=df2,aes(color="20"))
df1<-data.frame(x=c('SIFT','SIFT+HOG','SIFT+HOG+LBP','SIFT+HOG+Gray256'),
y=c(0.8267,0.8633,0.878,0.88),group=1)
df2<-data.frame(x=c('SIFT','SIFT+HOG','SIFT+HOG+LBP','SIFT+HOG+Gray256'),
y=c(0.8189,0.8667,0.877,0.89),group=1)
df3<-data.frame(x=c('SIFT','SIFT+HOG','SIFT+HOG+LBP','SIFT+HOG+Gray256'),
y=c(0.79,0.8344444,0.832222222,0.838888889),group=1)
ggplot(df1,aes(x,y,group=group))+geom_line(aes(color="GBM"))+
geom_line(data=df2,aes(color="xgboost"))+
geom_line(data=df3,aes(color="Random Forest"))+
labs(color="Model")+
xlab('Feature')+
ylab('Accuracy')+
ggtitle('Differnet Model with different feature')
df1<-data.frame(x=c('SIFT','SIFT+HOG','SIFT+HOG+LBP','SIFT+HOG+Gray256'),
y=c(0.8267,0.8633,0.872,0.88),group=1)
df2<-data.frame(x=c('SIFT','SIFT+HOG','SIFT+HOG+LBP','SIFT+HOG+Gray256'),
y=c(0.8189,0.8667,0.877,0.89),group=1)
df3<-data.frame(x=c('SIFT','SIFT+HOG','SIFT+HOG+LBP','SIFT+HOG+Gray256'),
y=c(0.79,0.8344444,0.832222222,0.838888889),group=1)
ggplot(df1,aes(x,y,group=group))+geom_line(aes(color="GBM"))+
geom_line(data=df2,aes(color="xgboost"))+
geom_line(data=df3,aes(color="Random Forest"))+
labs(color="Model")+
xlab('Feature')+
ylab('Accuracy')+
ggtitle('Differnet Model with different feature')
df1<-data.frame(x=c('SIFT','SIFT+HOG','SIFT+HOG+LBP','SIFT+HOG+LBP+Gray256'),
y=c(0.8267,0.8633,0.872,0.88),group=1)
df2<-data.frame(x=c('SIFT','SIFT+HOG','SIFT+HOG+LBP','SIFT+HOG+LBP+Gray256'),
y=c(0.8189,0.8667,0.877,0.89),group=1)
df3<-data.frame(x=c('SIFT','SIFT+HOG','SIFT+HOG+LBP','SIFT+HOG+LBP_Gray256'),
y=c(0.79,0.8344444,0.832222222,0.838888889),group=1)
ggplot(df1,aes(x,y,group=group))+geom_line(aes(color="GBM"))+
geom_line(data=df2,aes(color="xgboost"))+
geom_line(data=df3,aes(color="Random Forest"))+
labs(color="Model")+
xlab('Feature')+
ylab('Accuracy')+
ggtitle('Differnet Model with different feature')
df1<-data.frame(x=c('SIFT','SIFT+HOG','SIFT+HOG+LBP','SIFT+HOG+LBP+Gray256'),
y=c(0.8267,0.8633,0.872,0.88),group=1)
df2<-data.frame(x=c('SIFT','SIFT+HOG','SIFT+HOG+LBP','SIFT+HOG+LBP+Gray256'),
y=c(0.8189,0.8667,0.877,0.89),group=1)
df3<-data.frame(x=c('SIFT','SIFT+HOG','SIFT+HOG+LBP','SIFT+HOG+LBP+Gray256'),
y=c(0.79,0.8344444,0.832222222,0.838888889),group=1)
ggplot(df1,aes(x,y,group=group))+geom_line(aes(color="GBM"))+
geom_line(data=df2,aes(color="xgboost"))+
geom_line(data=df3,aes(color="Random Forest"))+
labs(color="Model")+
xlab('Feature')+
ylab('Accuracy')+
ggtitle('Differnet Model with different feature')
ggplot(df1,aes(x,y,group=group))+geom_line(aes(color="GBM"))+
geom_line(data=df2,aes(color="xgboost"))+
geom_line(data=df3,aes(color="Random Forest"))+
labs(color="Model")+
xlab('Feature')+
ylab('Accuracy')+
ggtitle('Differnet Model with different feature')+
theme(axis.text.x=element_text(angle=45, hjust=1))+
train_index <- sort(sample(1:length(label_train),0.7*length(label_train)))
ggplot(df1,aes(x,y,group=group))+geom_line(aes(color="GBM"))+
geom_line(data=df2,aes(color="xgboost"))+
geom_line(data=df3,aes(color="Random Forest"))+
labs(color="Model")+
xlab('Feature')+
ylab('Accuracy')+
ggtitle('Differnet Model with different feature')+
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(df1,aes(x,y,group=group))+geom_line(aes(color="GBM"))+
geom_line(data=df2,aes(color="xgboost"))+
geom_line(data=df3,aes(color="Random Forest"))+
labs(color="Model")+
xlab('Feature')+
ylab('Accuracy')+
ggtitle('Differnet Model with different feature')+
theme(axis.text.x=element_text(angle=135, hjust=1))
ggplot(df1,aes(x,y,group=group))+geom_line(aes(color="GBM"))+
geom_line(data=df2,aes(color="xgboost"))+
geom_line(data=df3,aes(color="Random Forest"))+
labs(color="Model")+
xlab('Feature')+
ylab('Accuracy')+
ggtitle('Differnet Model with different feature')+
theme(axis.text.x=element_text(angle=90, hjust=1))
ggplot(df1,aes(x,y,group=group))+geom_line(aes(color="GBM"))+
geom_line(data=df2,aes(color="xgboost"))+
geom_line(data=df3,aes(color="Random Forest"))+
labs(color="Model")+
xlab('Feature')+
ylab('Accuracy')+
ggtitle('Differnet Model with different feature')+
theme(axis.text.x=element_text(angle=45, hjust=1))
df1<-data.frame(x=c(150,250,300,500),y=rep(1,4)-c(0.271,0.255,0.25,0.228))
df2<-data.frame(x=c(150,250,300,500),y=rep(1,4)-c(0.203,0.199,0.206,0.191))
library(ggplot2)
ggplot(df1,aes(x,y))+geom_line(aes(color="0.01"))+
geom_line(data=df2,aes(color="0.1"))+
geom_point(c(0.1,250))
labs(color="shrinkage")+
xlab('Number of trees')+
ylab('Accuracy')+
ggtitle('GBM cross validation')
?geom_point
source('../lib/train.R')
source('../lib/cross_validation.R')
tm_train_xgb <- system.time(xgb_fit <- xgb_train(feature_train,label_train,run.cv=run.cv))[3]
feature_train <- get(load('../output/sift5000_lbp_hog_gray.RData'))
tm_train_xgb <- system.time(xgb_fit <- xgb_train(feature_train,label_train,run.cv=run.cv))[3]
run.cv=FALSE # run cross-validation on the training set
K_folds <- 3  # number of CV folds
run.feature.train=FALSE # process features for all pictures
run.train = FALSE # if true, train model on training data, else use saved model
run.test=TRUE # run evaluation on an independent test set
run.feature.test=FALSE # process features for test set
tm_train_xgb <- system.time(xgb_fit <- xgb_train(feature_train,label_train,run.cv=run.cv))[3]
save(xgb_fit,file='../output/xgb_fit.RData')
tm_train_xgb
list.of.packages <- c("e1071", "ggplot2","gbm","caret","randomForest","EBImage","xgboost","OpenImageR")
# new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
# if(length(new.packages))
#   {
#    install.packages(new.packages)
#    source("https://bioconductor.org/biocLite.R")
#    biocLite("EBImage")
#   }
packages.needed=setdiff(list.of.packages,
intersect(installed.packages()[,1],
list.of.packages))
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
library("gbm")
library("ggplot2")
library("caret")
library("randomForest")
library("EBImage")
library("xgboost")
library("OpenImageR")
label_train.dir <- '../data/label_train.csv'
feature_sift_train.dir <- '../data/sift_train.csv'
image_test.dir <- '../../data/images'
feature_sift_test.dir <- '../../data/sift_test.csv'
feature_hog_test.dir <- '../output/feature_hog_test.RData'
feature_lbp_test.dir <- '../output/feature_lbp_test.csv'
feature_gray_test.dir <- '../output/feature_gray_test.RData'
feature_test.dir <- '../output/feature_test.RData'
run.cv=FALSE # run cross-validation on the training set
K_folds <- 3  # number of CV folds
run.feature.train=FALSE # process features for all pictures
run.train = FALSE # if true, train model on training data, else use saved model
run.test=TRUE # run evaluation on an independent test set
run.feature.test=FALSE # process features for test set
label_train <- as.vector(read.csv(label_train.dir,as.is = T)[,2])
sift_train_feature <- read.csv(feature_sift_train.dir,as.is=T)[,-1]
source("../lib/feature.R")
feature_train <- get(load('../output/sift5000_lbp_hog_gray.RData'))
sift_test_feature <- read.csv(feature_sift_test.dir,as.is=T)[,-1]
tm_feature_hog <- system.time(feature_hog_test <-  HOG_extract(image_test.dir))
tm_feature_gray <- system.time(feature_gray_test <-  gray_extractFeature(image_test.dir))
source("../lib/feature.R")
gray_extractFeature(image_test.dir)
list.of.packages <- c("e1071", "ggplot2","gbm","caret","randomForest","EBImage","xgboost","OpenImageR","stringr")
# new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
# if(length(new.packages))
#   {
#    install.packages(new.packages)
#    source("https://bioconductor.org/biocLite.R")
#    biocLite("EBImage")
#   }
packages.needed=setdiff(list.of.packages,
intersect(installed.packages()[,1],
list.of.packages))
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
library("stringr")
library("gbm")
library("ggplot2")
library("caret")
library("randomForest")
library("EBImage")
library("xgboost")
library("OpenImageR")
tm_feature_gray <- system.time(feature_gray_test <-  gray_extractFeature(image_test.dir))
tm_feature_test <- tm_feature_gray + tm_feature_hog
save(feature_hog_test,file = feature_hog_test.dir)
save(feature_gray_test,file = feature_gray_test.dir)
load(feature_hog_test.dir)
load(feature_gray_test.dir)
feature_lbp_test <- read.csv(feature_lbp_test.dir,as.is=T)
feature_lbp_test <- read.csv(feature_lbp_test.dir,as.is=T)
feature_test <- cbind(sift_test_feature,feature_hog_test,feature_lbp_test,feature_gray_test)
View(feature_lbp_test)
View(feature_lbp_test)
feature_lbp_test <- read.csv(feature_lbp_test.dir,as.is=T)
dim(feature_lbp_test)
View(feature_lbp_test)
feature_lbp_test <- read.csv(feature_lbp_test.dir,as.is=T)[1:100,]
feature_test <- cbind(sift_test_feature,feature_hog_test,feature_lbp_test,feature_gray_test)
save(feature_test,file = feature_test.dir)
feature_test <- get(load(feature_test.dir)) # feature_test
source('../lib/train.R')
source('../lib/cross_validation.R')
if(run.train){
tm_train_base <- system.time(base_fit <-  gbm_train(sift_train_feature,label_train,run.cv = run.cv))[3]
save(base_fit,file='../output/base_fit.RData')
}else{
load('../output/base_fit.RData')
tm_train_base <- 152.279
}
if(run.train){
tm_train_xgb <- system.time(xgb_fit <- xgb_train(feature_train,label_train,run.cv=run.cv))[3]
save(xgb_fit,file='../output/xgb_fit.RData')
}else{
load('../output/xgb_fit.RData')
tm_train_xgb <- 193.722
}
sift_test_feature <- read.csv(feature_sift_test.dir,as.is = T)[,-1]
tm_predict_base <- system.time(pred_label_base <- gbm_test(base_fit,sift_test_feature))[3]
source('../lib/test.R')
tm_predict_base <- system.time(pred_label_base <- gbm_test(base_fit,sift_test_feature))[3]
tm_predict_xgb <- system.time(pred_label_xgb <- xgb_test(xgb_fit,feature_test))[3]
pred_label <- cbind(pred_label_base,pred_label_xgb)
write.csv(pred_label,'../output/labels.csv')
cat("Time for training model=", tm_train_base, "s \n")
cat("Time for making prediction=", tm_train_xgb, "s \n")
setwd("~/GitHub/Fall2017-project3-fall2017-project3-grp3/doc")
image_test.dir <- '../../../Desktop/Project 3/training_set/images/'
tm_feature_hog <- system.time(feature_hog_test <-  HOG_extract(image_test.dir))
tm_feature_hog
tm_feature_gray <- system.time(feature_gray_test <-  gray_extractFeature(image_test.dir))[3]
tm_feature_gray
list.of.packages <- c("e1071", "ggplot2","gbm","caret","randomForest","EBImage","xgboost","OpenImageR","stringr")
packages.needed=setdiff(list.of.packages,
intersect(installed.packages()[,1],
list.of.packages))
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
library("stringr")
library("gbm")
library("ggplot2")
library("caret")
library("randomForest")
library("EBImage")
library("xgboost")
library("OpenImageR")
#setwd('.')
#image_train.dir  # raw image folder
label_train.dir <- '../data/label_train.csv'
feature_sift_train.dir <- '../data/sift_train.csv'
# feature_hog_train.dir
# feature_lbp_train.dir
#
#
image_test.dir <- '../../data/images'
#
feature_sift_test.dir <- '../../data/sift_test.csv'
feature_hog_test.dir <- '../output/feature_hog_test.RData'
#feature_sift_pca_test.dir <- '../output/feature_sift_pca_test.RData'
feature_lbp_test.dir <- '../output/feature_lbp_test.RData'
feature_gray_test.dir <- '../output/feature_gray_test.RData'
feature_test.dir <- '../output/feature_test.RData'
#
# predict_label_base.dir
# predict_label_adv1.dir
# predict_label_adv2.dir
version
source('../lib/test.R')
load('../output/base_fit.RData')
setwd("~/GitHub/Fall2017-project3-fall2017-project3-grp3/doc")
load('../output/base_fit.RData')
load('../output/base_fit.RData')
load('../output/xgb_fit.RData')
tm_feature_hog <- system.time(feature_hog_test <-  HOG_extract(image_test.dir))[3]
source("../lib/feature.R")
tm_feature_hog <- system.time(feature_hog_test <-  HOG_extract(image_test.dir))[3]
tm_feature_gray <- system.time(feature_gray_test <-  gray_extractFeature(image_test.dir))[3]
save(feature_hog_test,file = feature_hog_test.dir)
save(feature_gray_test,file = feature_gray_test.dir)
feature_lbp_test <- get(load(feature_lbp_test.dir))
feature_test <- cbind(sift_test_feature,feature_hog_test,feature_lbp_test,feature_gray_test)
sift_test_feature <- read.csv(feature_sift_test.dir,as.is=T)[,-1]
feature_test <- cbind(sift_test_feature,feature_hog_test,feature_lbp_test,feature_gray_test)
save(feature_test,file = feature_test.dir)
tm_predict_xgb <- system.time(pred_label_xgb <- xgb_test(xgb_fit,feature_test))[3]
write.csv(pred_label_xgb,'../output/xgb_label.csv')
pred_label_xgb
source('../lib/train.R')
source('../lib/cross_validation.R')
tm_train_base <- system.time(base_fit <-  gbm_train(sift_train_feature,label_train,run.cv = run.cv))[3]
sift_train_feature <- read.csv(feature_sift_train.dir,as.is=T)[,-1]
label_train <- as.vector(read.csv(label_train.dir,as.is = T)[,2])
setwd("~/GitHub/Fall2017-project3-fall2017-project3-grp3/doc")
label_train <- as.vector(read.csv(label_train.dir,as.is = T)[,2])
