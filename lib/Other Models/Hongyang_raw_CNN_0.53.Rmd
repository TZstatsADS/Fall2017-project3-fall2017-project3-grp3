---
title: "ADS_Project3_CNN"
author: "Hongyang Yang"
date: "October 29, 2017"
output: html_document
---

```{r setup, include=FALSE}
library(EBImage)
library(stringr)
require(mxnet)
```

# 1 Data Handling
## 1.1 Load Image label

```{r}
label <- read.csv("../data/label_train.csv")
label <- label[,2]
```

## 1.1 sift features manipulate
```{r}
set.seed(1)

sift_features <- read.csv("../data/sift_train.csv",header = T)
sift_features=sift_features[,-1]
sift_index <- sample(3000, 3000*0.7)

train.sift.x<- sift_features[sift_index,]
train.sift.y <- label[sift_index]
train.sift.y=matrix(train.sift.y)

test.sift.x<- sift_features[-sift_index,]
test.sift.y <- label[-sift_index]
test.sift.y=matrix(test.sift.y)

train_sift <- data.frame(cbind(train.sift.y,train.sift.x))
test_sift <- data.frame(cbind(test.sift.y,test.sift.x))

#write.csv(train_sift,"../output/train_sift.csv",row.names = F)
#write.csv(test_sift,"../output/test_sift.csv",row.names = F)

```

## 1.2 Load Raw Image Information & Reshape to 28*28 Pixels
```{r}
img_dir <- "../data/images" #change to image directory

n_files <- length(list.files(img_dir))
imgvec <- matrix(NA, ncol = 28*28,nrow = 3000)

for(i in 1:n_files){
    ii <- str_pad(i, 4, pad = "0")
    #read image file
    img <- readImage(paste0(img_dir, "/","img_", ii,".jpg"))
    # Reshape as a 64x64 image (EBImage object)
    img <- Image(img, dim=c(64, 64), colormode = "Grayscale")
    # Resize image to 28x28 pixels
    img_resized <- resize(img,w=28,h=28)
    img_matrix <- img_resized@.Data
    # Coerce to a vector, 784
    img_temp <- as.vector(img_matrix)
    imgvec[i,] <- img_temp
}

save(imgvec, file="../output/CNN_features.RData")


```
## 1.3 Train-test split and save
```{r}
set.seed(1)
n=n_files
train_percentage = 0.7 # training set proportion

index <- sample(n, n*train_percentage)

train.cnn.x<- imgvec[index,]
train.cnn.y <- label[index]

test.cnn.x<- imgvec[-index,]
test.cnn.y <- label[-index]

train_cnn <- data.frame(cbind(train.cnn.y,train.cnn.x))
test_cnn <- data.frame(cbind(test.cnn.y,test.cnn.x))

#write.csv(train_cnn,"../output/train_cnn.csv",row.names = F)
#write.csv(test_cnn,"../output/test_cnn.csv",row.names = F)


```

# 2 Set up the mx symbolic model

```{r}
data <- mx.symbol.Variable('data')
# 1st convolutional layer
conv_1 <- mx.symbol.Convolution(data = data, kernel = c(5, 5), num_filter = 20)
tanh_1 <- mx.symbol.Activation(data = conv_1, act_type = "tanh")
pool_1 <- mx.symbol.Pooling(data = tanh_1, pool_type = "max", kernel = c(2, 2), stride = c(2, 2))
# 2nd convolutional layer
conv_2 <- mx.symbol.Convolution(data = pool_1, kernel = c(5, 5), num_filter = 50)
tanh_2 <- mx.symbol.Activation(data = conv_2, act_type = "tanh")
pool_2 <- mx.symbol.Pooling(data=tanh_2, pool_type = "max", kernel = c(2, 2), stride = c(2, 2))
# 1st fully connected layer
flatten <- mx.symbol.Flatten(data = pool_2)
fc_1 <- mx.symbol.FullyConnected(data = flatten, num_hidden = 500)
tanh_3 <- mx.symbol.Activation(data = fc_1, act_type = "tanh")
# 2nd fully connected layer
fc_2 <- mx.symbol.FullyConnected(data = tanh_3, num_hidden = 40)
# Output. Softmax output since we'd like to get some probabilities.
NN_model <- mx.symbol.SoftmaxOutput(data = fc_2)

```

# 3 Set up CNN Model train and test datasets
```{r}
train <- read.csv("../output/train_cnn.csv")
test <- read.csv("../output/test_cnn.csv")

#train <- read.csv("../output/train_sift.csv")
#test <- read.csv("../output/test_sift.csv")

# Set up train and test datasets
train <- data.matrix(train)
train_x <- t(train[, -1])
train_y <- train[, 1]
train_array <- train_x
dim(train_array) <- c(28, 28, 1, ncol(train_x))

test_x <- t(test[, -1])
test_y <- test[, 1]
test_array <- test_x
dim(test_array) <- c(28, 28, 1, ncol(test_x))

```

# 4 Train the CNN model

```{r}
devices <- mx.cpu()
start.time <- Sys.time()

model <- mx.model.FeedForward.create(NN_model,
                                     X = train_array,
                                     y = train_y,
                                     ctx = devices,
                                     num.round = 300,
                                     array.batch.size = 40,
                                     learning.rate = 0.01,
                                     momentum = 0.9,
                                     eval.metric = mx.metric.accuracy,
                                     epoch.end.callback = mx.callback.log.train.metric(100))
end.time <- Sys.time()
CNN_runtime <- end.time-start.time
CNN_runtime

save(model, file = "CNN_model.rda")

```
# 5 Testing

```{r}

# Predict labels
predicted <- predict(model, test_array)
# Assign labels
predicted_labels <- max.col(t(predicted)) - 1
# Get accuracy
sum(diag(table(test[, 1], predicted_labels)))/900
# Get Test error
test_error <- mean(predicted_labels != test[, 1])
test_error
```

```{r}

```